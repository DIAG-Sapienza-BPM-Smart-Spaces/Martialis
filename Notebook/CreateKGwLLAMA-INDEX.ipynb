{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4b6d1ecc-8d66-466d-b713-139daa5c4c43",
   "metadata": {},
   "source": [
    "# Setup\n",
    "Ho avuto problemi con il mio neo4j locale quindi nel dubbio ho usato quello su docker\n",
    "```sh\n",
    "docker run \\\n",
    "    -p 7474:7474 -p 7687:7687 \\\n",
    "    -v $PWD/data:/data -v $PWD/plugins:/plugins \\\n",
    "    --name neo4j-apoc \\\n",
    "    -e NEO4J_apoc_export_file_enabled=true \\\n",
    "    -e NEO4J_apoc_import_file_enabled=true \\\n",
    "    -e NEO4J_apoc_import_file_use__neo4j__config=true \\\n",
    "    -e NEO4JLABS_PLUGINS=\\[\\\"apoc\\\"\\] \\\n",
    "    neo4j:latest\n",
    "```\n",
    "E poi connessione su [localhost:7474](localhost:7474)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b879b6-440b-434a-912f-db50aa18827e",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install pip install llama-index-graph-stores-neo4j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "620399ee-e9c3-4594-87a4-f1bff484172d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio; nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ee7400-81f6-42ed-9d5e-265f8e6ded7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"\" # Add your OpenAI API key here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "90a29d80-bffa-4470-8b9b-572831c26cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "083e4a48-a788-44f7-a7d7-c83d20e5332d",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = SimpleDirectoryReader('').load_data() # Add the path to the directory containing your documents here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "870adbea-7dac-4974-b98f-222b542c9517",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.graph_stores.neo4j import Neo4jPropertyGraphStore\n",
    "\n",
    "# Note: used to be `Neo4jPGStore`\n",
    "graph_store = Neo4jPropertyGraphStore(\n",
    "    username=\"neo4j\",\n",
    "    password=\"hackaton\",\n",
    "    url=\"bolt://localhost:7687\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8b9bbc03-b309-4e6f-bc6b-0b5648aa1efb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "056d0520031c464fb633b19794c37643",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Parsing nodes:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting paths from text: 100%|█████████████████| 2/2 [00:02<00:00,  1.42s/it]\n",
      "Extracting implicit paths: 100%|███████████████| 2/2 [00:00<00:00, 11110.74it/s]\n",
      "Generating embeddings: 100%|██████████████████████| 1/1 [00:00<00:00,  1.20it/s]\n",
      "Generating embeddings: 100%|██████████████████████| 1/1 [00:01<00:00,  1.39s/it]\n",
      "Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.AggregationSkippedNull} {category: UNRECOGNIZED} {title: The query contains an aggregation function that skips null values.} {description: null value eliminated in set function.} {position: None} for query: \"MATCH (n:`Chunk`)\\nWITH collect(distinct substring(toString(coalesce(n.`doc_id`, '')), 0, 50)) AS `doc_id_values`,\\n     collect(distinct substring(toString(coalesce(n.`_node_type`, '')), 0, 50)) AS `_node_type_values`,\\n     collect(distinct substring(toString(coalesce(n.`_node_content`, '')), 0, 50)) AS `_node_content_values`,\\n     min(size(coalesce(n.`embedding`, []))) AS `embedding_size_min`, max(size(coalesce(n.`embedding`, []))) AS `embedding_size_max`,\\n     collect(distinct substring(toString(coalesce(n.`document_id`, '')), 0, 50)) AS `document_id_values`,\\n     collect(distinct substring(toString(coalesce(n.`creation_date`, '')), 0, 50)) AS `creation_date_values`,\\n     collect(distinct substring(toString(coalesce(n.`file_path`, '')), 0, 50)) AS `file_path_values`,\\n     min(n.`file_size`) AS `file_size_min`,\\n     max(n.`file_size`) AS `file_size_max`,\\n     count(distinct n.`file_size`) AS `file_size_distinct`,\\n     collect(distinct substring(toString(coalesce(n.`file_type`, '')), 0, 50)) AS `file_type_values`,\\n     collect(distinct substring(toString(coalesce(n.`last_modified_date`, '')), 0, 50)) AS `last_modified_date_values`,\\n     collect(distinct substring(toString(coalesce(n.`ref_doc_id`, '')), 0, 50)) AS `ref_doc_id_values`,\\n     collect(distinct substring(toString(coalesce(n.`id`, '')), 0, 50)) AS `id_values`,\\n     collect(distinct substring(toString(coalesce(n.`text`, '')), 0, 50)) AS `text_values`,\\n     collect(distinct substring(toString(coalesce(n.`file_name`, '')), 0, 50)) AS `file_name_values`\\nRETURN {`doc_id`: {values:`doc_id_values`[..10], distinct_count: size(`doc_id_values`)}, `_node_type`: {values:`_node_type_values`[..10], distinct_count: size(`_node_type_values`)}, `_node_content`: {values:`_node_content_values`[..10], distinct_count: size(`_node_content_values`)}, `embedding`: {min_size: `embedding_size_min`, max_size: `embedding_size_max`}, `document_id`: {values:`document_id_values`[..10], distinct_count: size(`document_id_values`)}, `creation_date`: {values:`creation_date_values`[..10], distinct_count: size(`creation_date_values`)}, `file_path`: {values:`file_path_values`[..10], distinct_count: size(`file_path_values`)}, `file_size`: {min: toString(`file_size_min`), max: toString(`file_size_max`), distinct_count: `file_size_distinct`}, `file_type`: {values:`file_type_values`[..10], distinct_count: size(`file_type_values`)}, `last_modified_date`: {values:`last_modified_date_values`[..10], distinct_count: size(`last_modified_date_values`)}, `ref_doc_id`: {values:`ref_doc_id_values`[..10], distinct_count: size(`ref_doc_id_values`)}, `id`: {values:`id_values`[..10], distinct_count: size(`id_values`)}, `text`: {values:`text_values`[..10], distinct_count: size(`text_values`)}, `file_name`: {values:`file_name_values`[..10], distinct_count: size(`file_name_values`)}} AS output\"\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core import PropertyGraphIndex\n",
    "from llama_index.core.indices.property_graph import SchemaLLMPathExtractor\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "from llama_index.llms.openai import OpenAI\n",
    "\n",
    "\n",
    "# create\n",
    "index = PropertyGraphIndex.from_documents(\n",
    "    documents,\n",
    "    llm=OpenAI(\"gpt-4o\"),\n",
    "    embed_model=OpenAIEmbedding(model_name=\"text-embedding-3-small\"),\n",
    "    property_graph_store=graph_store,\n",
    "    show_progress=True,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
