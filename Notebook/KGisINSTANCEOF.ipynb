{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4b6d1ecc-8d66-466d-b713-139daa5c4c43",
   "metadata": {},
   "source": [
    "# Setup\n",
    "Ho avuto problemi con il mio neo4j locale quindi nel dubbio ho usato quello su docker\n",
    "```sh\n",
    "docker run \\\n",
    "    -p 7474:7474 -p 7687:7687 \\\n",
    "    -v $PWD/data:/data -v $PWD/plugins:/plugins \\\n",
    "    --name neo4j-apoc \\\n",
    "    -e NEO4J_apoc_export_file_enabled=true \\\n",
    "    -e NEO4J_apoc_import_file_enabled=true \\\n",
    "    -e NEO4J_apoc_import_file_use__neo4j__config=true \\\n",
    "    -e NEO4JLABS_PLUGINS=\\[\\\"apoc\\\"\\] \\\n",
    "    neo4j:latest\n",
    "```\n",
    "E poi connessione su [localhost:7474](localhost:7474)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b879b6-440b-434a-912f-db50aa18827e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "! pip install llama-index llama-index-graph-stores-neo4j llama-index-embeddings-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "620399ee-e9c3-4594-87a4-f1bff484172d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio; nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ee7400-81f6-42ed-9d5e-265f8e6ded7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"\" # Set your OpenAI API key here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "90a29d80-bffa-4470-8b9b-572831c26cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "27a591d4-37a3-4980-a04c-b5d4115137a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import uuid\n",
    "\n",
    "# Create a temporary folder to store in-memory files in, which is removed after use.\n",
    "# Takes a dictionary of the form {filename: bytes} so it also works for non-streamlit applications.\n",
    "# Note that this removes all file metadata.\n",
    "class TempDir:\n",
    "    def __init__(self, files):\n",
    "        # This assumes Unix-like filesystem.\n",
    "        # Consider using the tempfile module to make it cross-platform\n",
    "        self.tmpdir = os.path.join(\"/tmp/upload/\", str(uuid.uuid4()))\n",
    "        self.files = files\n",
    "\n",
    "    def __enter__(self):\n",
    "        os.makedirs(self.tmpdir)\n",
    "        for filename, file_bytes in self.files.items():\n",
    "            file_path = os.path.join(self.tmpdir, filename)\n",
    "            with open(file_path, 'wb') as f:\n",
    "                f.write(file_bytes)\n",
    "        return self.tmpdir\n",
    "\n",
    "    def __exit__(self, exc_type, exc_value, exc_traceback):\n",
    "        for filename in self.files.keys():\n",
    "            file_path = os.path.join(self.tmpdir, filename)\n",
    "            os.remove(file_path)\n",
    "        os.rmdir(self.tmpdir)\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "903964b2-f6e5-4fe7-b82b-231a4979a4b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_dict = {\"test\": \"\"\"Cartella Clinica di Dimissione\n",
    "Paziente: Mario Rossi\n",
    "Data di Dimissione: 26 novembre 2024\n",
    "\n",
    "Diagnosi:\n",
    "\n",
    "Polmonite interstiziale bilaterale di origine virale.\n",
    "Trattamento Somministrato:\n",
    "\n",
    "Terapia antibiotica con Ceftriaxone 1g/die per via endovenosa per 7 giorni.\n",
    "Terapia di supporto con ossigenoterapia a basso flusso.\n",
    "Esami Diagnostici:\n",
    "\n",
    "Radiografia del torace: infiltrati polmonari bilaterali di tipo reticolare.\n",
    "Emogasanalisi: lieve ipossiemia (PaO2 65 mmHg).\n",
    "PCR (Proteina C-Reattiva): 85 mg/L (ridotta a 25 mg/L dopo la terapia).\n",
    "Prossimi Passi e Raccomandazioni:\n",
    "\n",
    "Visite di controllo: appuntamento con il pneumologo tra 14 giorni.\n",
    "Continuare terapia domiciliare con Amoxicillina 500 mg ogni 8 ore per 5 giorni.\n",
    "Eseguire nuova radiografia del torace tra 1 mese per monitorare il recupero.\n",
    "Medico Responsabile:\n",
    "\n",
    "Dr. Anna Bianchi\n",
    "Reparto di Pneumologia, Ospedale Santa Maria, Roma\n",
    "Telefono: +39 06 1234567\n",
    "\"\"\".encode()}\n",
    "with TempDir(file_dict) as tempdir:\n",
    "    documents = SimpleDirectoryReader(input_dir=tempdir).load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "083e4a48-a788-44f7-a7d7-c83d20e5332d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#documents = SimpleDirectoryReader(\"/Users/marcocalamo/Downloads/txt\").load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "64461e96-883f-4376-a4b2-ba9dee342d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.graph_stores.neo4j import Neo4jPropertyGraphStore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "870adbea-7dac-4974-b98f-222b542c9517",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neo4j.notifications:Received notification from DBMS server: {severity: INFORMATION} {code: Neo.ClientNotification.Schema.IndexOrConstraintAlreadyExists} {category: SCHEMA} {title: `CREATE CONSTRAINT IF NOT EXISTS FOR (e:__Node__) REQUIRE (e.id) IS UNIQUE` has no effect.} {description: `CONSTRAINT constraint_ec67c859 FOR (e:__Node__) REQUIRE (e.id) IS UNIQUE` already exists.} {position: None} for query: 'CREATE CONSTRAINT IF NOT EXISTS FOR (n:`__Node__`)\\n            REQUIRE n.id IS UNIQUE;'\n",
      "INFO:neo4j.notifications:Received notification from DBMS server: {severity: INFORMATION} {code: Neo.ClientNotification.Schema.IndexOrConstraintAlreadyExists} {category: SCHEMA} {title: `CREATE CONSTRAINT IF NOT EXISTS FOR (e:__Entity__) REQUIRE (e.id) IS UNIQUE` has no effect.} {description: `CONSTRAINT constraint_907a464e FOR (e:__Entity__) REQUIRE (e.id) IS UNIQUE` already exists.} {position: None} for query: 'CREATE CONSTRAINT IF NOT EXISTS FOR (n:`__Entity__`)\\n            REQUIRE n.id IS UNIQUE;'\n",
      "INFO:neo4j.notifications:Received notification from DBMS server: {severity: INFORMATION} {code: Neo.ClientNotification.Schema.IndexOrConstraintAlreadyExists} {category: SCHEMA} {title: `CREATE VECTOR INDEX entity IF NOT EXISTS FOR (e:__Entity__) ON (e.embedding)` has no effect.} {description: `VECTOR INDEX entity FOR (e:__Entity__) ON (e.embedding)` already exists.} {position: None} for query: 'CREATE VECTOR INDEX entity IF NOT EXISTS FOR (m:__Entity__) ON m.embedding'\n"
     ]
    }
   ],
   "source": [
    "# Note: used to be `Neo4jPGStore`\n",
    "graph_store = Neo4jPropertyGraphStore(\n",
    "    username=\"neo4j\",\n",
    "    password=\"hackaton\",\n",
    "    url=\"bolt://localhost:7687\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f2c4990-7da5-4777-92d7-88807d9e4cb6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "! pip install deeponto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "132a0eca-7f32-444e-bd9e-cb3422ea59c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please enter the maximum memory located to JVM [8g]:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:deeponto:8g maximum memory allocated to JVM.\n",
      "INFO:deeponto:JVM started successfully.\n"
     ]
    }
   ],
   "source": [
    "# parse ontology\n",
    "from deeponto.onto import Ontology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b226ab7-a186-41fc-91b1-734ef915fbaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "onto = Ontology(\"/Users/marcocalamo/multi_ont.owl\", \"elk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "38092bb5-1d67-4a8b-80db-187ee387700a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from llama_index.llms.openai import OpenAI\n",
    "\n",
    "#response = OpenAI().complete(\"Paul Graham is \")\n",
    "#print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db414562-04de-4210-8615-7a2c2edcece0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#stream = OpenAI().stream_complete(\"Hi, write a short story\")\n",
    "\n",
    "#s=''\n",
    "#for r in stream:\n",
    "#    print(r.delta, end=\"\")\n",
    "#    s += r.delta\n",
    "#print()\n",
    "#print('---------')\n",
    "#print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06b0c119-35a8-42d4-bddc-6141beda3519",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "onto.owl_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "487c4148-77e6-4c09-9a6c-824fc4d9b4ca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ent = []\n",
    "for s,_ in onto.owl_classes.items():\n",
    "    print(s.split('#')[1])\n",
    "    ent.append(s.split('#')[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2882601-5e65-48d4-9e11-9619336af338",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rel = []\n",
    "for s,_ in onto.owl_object_properties.items():\n",
    "    print(s.split('#')[1])\n",
    "    rel.append(s.split('#')[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3fd3d7e-3081-45e4-9b09-00ff8d8d820f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for s,_ in onto.owl_data_properties.items():\n",
    "    print(s.split('#')[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "10b08a5f-e072-427a-9bb8-59d3bb35f62e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "from llama_index.core.indices.property_graph import SchemaLLMPathExtractor\n",
    "\n",
    "from llama_index.llms.openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea326b4-52a6-490f-81aa-f36e50c8279d",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(\"gpt-4-turbo\")\n",
    "\n",
    "\n",
    "# recommended uppercase, underscore separated\n",
    "entities = Literal[tuple([re.sub(r'(?<!^)(?=[A-Z])', '_', e).upper() for e in ent])]\n",
    "relations = Literal[tuple([re.sub(r'(?<!^)(?=[A-Z])', '_', r).upper() for r in rel])]\n",
    "schema = {\n",
    "    \"PERSON\": [\"PART_OF\", \"HAS\", \"IS_A\"],\n",
    "    \"PLACE\": [\"PART_OF\", \"HAS\"],\n",
    "    \"THING\": [\"IS_A\"],\n",
    "}\n",
    "\n",
    "kg_extractor = SchemaLLMPathExtractor(\n",
    "    llm=llm,\n",
    "    possible_entities=entities,\n",
    "    possible_relations=relations,\n",
    "    #kg_validation_schema=schema,\n",
    "    strict=False,  # if false, will allow triplets outside of the schema\n",
    "    num_workers=4,\n",
    "    max_triplets_per_chunk=10,\n",
    ")\n",
    "\n",
    "\"\"\"\n",
    "from llama_index.core.indices.property_graph import DynamicLLMPathExtractor\n",
    "import re\n",
    "\n",
    "kg_extractor = DynamicLLMPathExtractor(\n",
    "    llm=llm,\n",
    "    max_triplets_per_chunk=20,\n",
    "    num_workers=4,\n",
    "    allowed_entity_types=[re.sub(r'(?<!^)(?=[A-Z])', '_', e).upper() for e in ent],\n",
    "    allowed_relation_types=[re.sub(r'(?<!^)(?=[A-Z])', '_', r).upper() for r in rel],\n",
    ")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ebd64ed6-5709-46df-80af-950f02e861b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import PropertyGraphIndex\n",
    "from llama_index.core.indices.property_graph import SchemaLLMPathExtractor\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b9bbc03-b309-4e6f-bc6b-0b5648aa1efb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# create\n",
    "index = PropertyGraphIndex.from_documents(\n",
    "    documents,\n",
    "    kg_extractors=[kg_extractor],\n",
    "    property_graph_store=graph_store,\n",
    "    show_progress=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9edae603-9bc9-424e-b9da-3b4ceef8af2b",
   "metadata": {},
   "source": [
    "# Format Everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "873a5476-7913-40a4-b7e6-9b04276c0cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_label_usage_percentage(uri, user, password, reference_labels):\n",
    "    \"\"\"\n",
    "    Computes the percentage of distinct labels in the database that are part of a reference list.\n",
    "\n",
    "    Args:\n",
    "        uri (str): The URI of the Neo4j database (e.g., \"bolt://localhost:7687\").\n",
    "        user (str): The username for authentication.\n",
    "        password (str): The password for authentication.\n",
    "        reference_labels (list): A list of reference labels to compare against.\n",
    "\n",
    "    Returns:\n",
    "        float: The percentage of distinct labels used in the database that match the reference list.\n",
    "        list: The labels found in both the database and the reference list.\n",
    "    \"\"\"\n",
    "    query = \"\"\"\n",
    "    MATCH (n)\n",
    "    WITH DISTINCT labels(n) AS labels\n",
    "    UNWIND labels AS label\n",
    "    RETURN DISTINCT label\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Initialize the driver\n",
    "        driver = GraphDatabase.driver(uri, auth=(user, password))\n",
    "        \n",
    "        # Run the query and collect results\n",
    "        with driver.session() as session:\n",
    "            result = session.run(query)\n",
    "            db_labels = {record[\"label\"] for record in result}  # Use a set for fast lookups\n",
    "        \n",
    "        # Find the intersection of database labels and reference labels\n",
    "        reference_set = set(reference_labels)\n",
    "        common_labels = db_labels.intersection(reference_set)\n",
    "        \n",
    "        # Calculate the percentage\n",
    "        percentage = (len(common_labels) / len(reference_set)) * 100 if reference_set else 0\n",
    "        \n",
    "        return percentage, list(common_labels)\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return 0, []\n",
    "    \n",
    "    finally:\n",
    "        # Close the driver\n",
    "        driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3f52c22f-4a1a-4eea-8135-7eb5a7b804fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_relationship_type_usage_percentage(uri, user, password, reference_relationship_types):\n",
    "    \"\"\"\n",
    "    Computes the percentage of distinct relationship types in the database that are part of a reference list.\n",
    "\n",
    "    Args:\n",
    "        uri (str): The URI of the Neo4j database (e.g., \"bolt://localhost:7687\").\n",
    "        user (str): The username for authentication.\n",
    "        password (str): The password for authentication.\n",
    "        reference_relationship_types (list): A list of reference relationship types to compare against.\n",
    "\n",
    "    Returns:\n",
    "        float: The percentage of distinct relationship types used in the database that match the reference list.\n",
    "        list: The relationship types found in both the database and the reference list.\n",
    "    \"\"\"\n",
    "    query = \"\"\"\n",
    "    MATCH ()-[r]-()\n",
    "    RETURN DISTINCT type(r) AS relationship_type\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Initialize the driver\n",
    "        driver = GraphDatabase.driver(uri, auth=(user, password))\n",
    "        \n",
    "        # Run the query and collect results\n",
    "        with driver.session() as session:\n",
    "            result = session.run(query)\n",
    "            db_relationship_types = {record[\"relationship_type\"] for record in result}  # Use a set for fast lookups\n",
    "        \n",
    "        # Find the intersection of database relationship types and reference list\n",
    "        reference_set = set(reference_relationship_types)\n",
    "        common_relationship_types = db_relationship_types.intersection(reference_set)\n",
    "        \n",
    "        # Calculate the percentage\n",
    "        percentage = (len(common_relationship_types) / len(reference_set)) * 100 if reference_set else 0\n",
    "        \n",
    "        return percentage, list(common_relationship_types)\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return 0, []\n",
    "    \n",
    "    finally:\n",
    "        # Close the driver\n",
    "        driver.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "16baf6e5-dbb5-4e27-b568-eadec0443c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "uri = \"bolt://localhost:7687\"\n",
    "user = \"neo4j\"\n",
    "password = \"hackaton\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cded3215-870e-4872-bf21-d49a984aba86",
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_label_usage_percentage(uri, user, password, [re.sub(r'(?<!^)(?=[A-Z])', '_', e).upper() for e in ent])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ece8049f-74fc-45b9-9342-8bd323c41204",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "compute_relationship_type_usage_percentage(uri, user, password, [re.sub(r'(?<!^)(?=[A-Z])', '_', e).upper() for e in rel])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "3b3f786d-27e0-44be-9e9b-9a00d854edaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def docs2neo4j(documents):\n",
    "    llm = OpenAI(\"gpt-4o-mini\")\n",
    "\n",
    "    ent, rel = extract_ent_rel_2()\n",
    "\n",
    "    # recommended uppercase, underscore separated\n",
    "    entities = Literal[tuple([re.sub(r'(?<!^)(?=[A-Z])', '_', e).upper() for e in ent])]\n",
    "    relations = Literal[tuple([re.sub(r'(?<!^)(?=[A-Z])', '_', r).upper() for r in rel])]\n",
    "    \n",
    "    \n",
    "    kg_extractor = SchemaLLMPathExtractor(\n",
    "        llm=llm,\n",
    "        possible_entities=entities,\n",
    "        possible_relations=relations,\n",
    "        #kg_validation_schema=schema,\n",
    "        strict=False,  # if false, will allow triplets outside of the schema\n",
    "        num_workers=4,\n",
    "        max_triplets_per_chunk=10,\n",
    "    )\n",
    "\n",
    "    # Note: used to be `Neo4jPGStore`\n",
    "    graph_store = Neo4jPropertyGraphStore(\n",
    "        username=\"neo4j\",\n",
    "        password=\"hackaton\",\n",
    "        url=\"bolt://localhost:7687\",\n",
    "    )\n",
    "\n",
    "    index = PropertyGraphIndex.from_documents(\n",
    "        documents,\n",
    "        kg_extractors=[kg_extractor],\n",
    "        property_graph_store=graph_store,\n",
    "        show_progress=True,\n",
    "    )\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "18a89999-a3da-475a-90de-03fe284d9ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pialla_neo4j():\n",
    "    query = \"\"\"\n",
    "        MATCH (n)\n",
    "        DETACH DELETE (n)\n",
    "        \"\"\"\n",
    "    try:\n",
    "        # Initialize the driver\n",
    "        driver = GraphDatabase.driver(uri, auth=(user, password))\n",
    "        \n",
    "        # Run the query and collect results\n",
    "        with driver.session() as session:\n",
    "            result = session.run(query)\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "342f0fb0-2be1-47c4-ad99-e531c9e11ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def txt2doc(txt):\n",
    "    file_dict = {\"test\": open(txt, \"r\", errors='ignore').read().encode()}\n",
    "    with TempDir(file_dict) as tempdir:\n",
    "        documents = SimpleDirectoryReader(input_dir=tempdir).load_data()\n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "fb57783d-1dd1-4690-a0cf-bb1d507d3fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_ent_rel():\n",
    "    onto = Ontology(\"/Users/marcocalamo/multi_ont.owl\", \"elk\")\n",
    "    ent = [\"Document\", \"Patient\", \"Treatment\", \"Medical Test\",\"Diagnostic\",\n",
    "           \"Result\",\"Outcome\",\"Therapy\",\"Drug\", \"Family History Role\",\n",
    "           \"Treatment Association\", \"Specialist\", \"Side Effect\",\n",
    "           \"Comorbidity Interaction\", \"Test Dependency\"]\n",
    "\n",
    "    #for s,_ in onto.owl_classes.items():\n",
    "    #    #print(s.split('#')[1])\n",
    "    #    ent.append(s.split('#')[1])\n",
    "        \n",
    "\n",
    "    rel = [\"hasPatient\", \"hasTreatment\", \"hasMedicalTest\", \"hasDiagnostic\",\n",
    "           \"hasResult\", \"hasOutcome\", \"hasTherapy\", \"hasDrug\", \"hasFamilyHistoryRole\",\n",
    "           \"hasTreatmentAssociation\", \"hasSpecialist\", \"hasSideEffect\", \"hasComorbidityInteraction\", \n",
    "           \"hasTestDependency\"]\n",
    "    #for s,_ in onto.owl_object_properties.items():\n",
    "    #    #print(s.split('#')[1])\n",
    "    #    rel.append(s.split('#')[1])\n",
    "\n",
    "    entities = [re.sub(r'(?<!^)(?=[A-Z])', '_', e).upper() for e in ent]\n",
    "    relations = [re.sub(r'(?<!^)(?=[A-Z])', '_', r).upper() for r in rel]\n",
    "\n",
    "    #print(entities, relations)\n",
    "\n",
    "    return entities, relations\n",
    "\n",
    "def extract_ent_rel_2():\n",
    "    onto = Ontology(\"/Users/marcocalamo/multi_ont.owl\", \"elk\")\n",
    "    ent = [\"Document\", \"Patient\", \"Treatment\", \"Medical Test\",\"Diagnostic\",\n",
    "       \"Result\",\"Outcome\",\"Therapy\",\"Drug\", \"Family History Role\",\n",
    "       \"Treatment Association\", \"Specialist\", \"Side Effect\",\n",
    "       \"Comorbidity Interaction\", \"Test Dependency\"]\n",
    "\n",
    "    #for s,_ in onto.owl_classes.items():\n",
    "    #    #print(s.split('#')[1])\n",
    "    #    ent.append(s.split('#')[1])\n",
    "        \n",
    "\n",
    "    rel = [\"hasPatient\", \"hasTreatment\", \"hasMedicalTest\", \"hasDiagnostic\",\n",
    "           \"hasResult\", \"hasOutcome\", \"hasTherapy\", \"hasDrug\", \"hasFamilyHistoryRole\",\n",
    "           \"hasTreatmentAssociation\", \"hasSpecialist\", \"hasSideEffect\", \"hasComorbidityInteraction\", \n",
    "           \"hasTestDependency\"]\n",
    "\n",
    "    return ent, rel\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "dec0a388-2432-4345-a18f-2b061f170bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openpyxl\n",
    "from openpyxl import load_workbook\n",
    "\n",
    "\n",
    "def valuta_txt_ent():\n",
    "    ent, rel = extract_ent_rel()\n",
    "    uri = \"bolt://localhost:7687\"\n",
    "    user = \"neo4j\"\n",
    "    password = \"hackaton\"\n",
    "    res = compute_label_usage_percentage(uri, user, password, ent)\n",
    "\n",
    "    return res\n",
    "\n",
    "def valuta_txt_rel():\n",
    "    ent, rel = extract_ent_rel()\n",
    "    uri = \"bolt://localhost:7687\"\n",
    "    user = \"neo4j\"\n",
    "    password = \"hackaton\"\n",
    "    res = compute_relationship_type_usage_percentage(uri, user, password, rel)\n",
    "\n",
    "    return res\n",
    "    \n",
    "    \n",
    "\n",
    "def genera_excel_con_valutazione(input_txt, output_excel):\n",
    "    \"\"\"\n",
    "    Legge un file txt, chiama una funzione di valutazione e salva i risultati in un file Excel.\n",
    "    \n",
    "    Args:\n",
    "        input_txt (str): Percorso del file .txt da valutare.\n",
    "        output_excel (str): Percorso del file .xlsx generato.\n",
    "    \"\"\"\n",
    "\n",
    "    nome_txt = input_txt.split(\"/\")[-1]  # Estrae il nome del file\n",
    "\n",
    "    # Crea doc\n",
    "    document = txt2doc(input_txt)\n",
    "    \n",
    "    # Riempi neo4j\n",
    "    docs2neo4j(document)\n",
    "    \n",
    "    # Ottieni la valutazione e le entità trovate\n",
    "    valutazione, entita_trovate = valuta_txt_ent()\n",
    "    \n",
    "    # Tronca la valutazione al secondo decimale\n",
    "    valutazione_troncata = round(valutazione, 2)\n",
    "    \n",
    "    # Prepara i dati da salvare\n",
    "    entita_str = \", \".join(entita_trovate)  # Formatta le entità come stringa\n",
    "\n",
    "    # Ottieni la valutazione e le entità trovate\n",
    "    valutazione_rel, rel_trovate = valuta_txt_rel()\n",
    "    \n",
    "    # Tronca la valutazione al secondo decimale\n",
    "    valutazione_r_troncata = round(valutazione_rel, 2)\n",
    "    \n",
    "    # Prepara i dati da salvare\n",
    "    rel_str = \", \".join(rel_trovate)  # Formatta le entità come stringa\n",
    "    \n",
    "   # Verifica se il file Excel esiste\n",
    "    if os.path.exists(output_excel):\n",
    "        # Carica il file esistente\n",
    "        wb = load_workbook(output_excel)\n",
    "        ws = wb.active\n",
    "    else:\n",
    "        # Crea un nuovo file Excel\n",
    "        wb = openpyxl.Workbook()\n",
    "        ws = wb.active\n",
    "        ws.title = \"Valutazioni\"\n",
    "        # Scrivi l'intestazione\n",
    "        ws.append([\"nome_txt\", \"valutazione_ent\", \"entita_trovate\", \"valutazione_rel\", \"rel_trovate\"])\n",
    "    \n",
    "    # Scrivi i dati\n",
    "    ws.append([nome_txt, valutazione_troncata, entita_str, valutazione_r_troncata, rel_str])\n",
    "    \n",
    "    # Salva il file Excel\n",
    "    wb.save(output_excel)\n",
    "    print(f\"File Excel salvato in: {output_excel}\")\n",
    "\n",
    "    pialla_neo4j()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf1277fa-1f8f-4b7c-92c7-9c3ba377e7a8",
   "metadata": {},
   "source": [
    "# Valuta txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "51b0d136-6c9f-499c-a9cf-f212e924a020",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neo4j import GraphDatabase\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "9cf56ece-9d7f-4f02-a8f2-78ca22d8bbfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "pialla_neo4j()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "a63210fd-f817-495e-89cc-17730da486f4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:neo4j.notifications:Received notification from DBMS server: {severity: INFORMATION} {code: Neo.ClientNotification.Schema.IndexOrConstraintAlreadyExists} {category: SCHEMA} {title: `CREATE CONSTRAINT IF NOT EXISTS FOR (e:__Node__) REQUIRE (e.id) IS UNIQUE` has no effect.} {description: `CONSTRAINT constraint_ec67c859 FOR (e:__Node__) REQUIRE (e.id) IS UNIQUE` already exists.} {position: None} for query: 'CREATE CONSTRAINT IF NOT EXISTS FOR (n:`__Node__`)\\n            REQUIRE n.id IS UNIQUE;'\n",
      "INFO:neo4j.notifications:Received notification from DBMS server: {severity: INFORMATION} {code: Neo.ClientNotification.Schema.IndexOrConstraintAlreadyExists} {category: SCHEMA} {title: `CREATE CONSTRAINT IF NOT EXISTS FOR (e:__Entity__) REQUIRE (e.id) IS UNIQUE` has no effect.} {description: `CONSTRAINT constraint_907a464e FOR (e:__Entity__) REQUIRE (e.id) IS UNIQUE` already exists.} {position: None} for query: 'CREATE CONSTRAINT IF NOT EXISTS FOR (n:`__Entity__`)\\n            REQUIRE n.id IS UNIQUE;'\n",
      "INFO:neo4j.notifications:Received notification from DBMS server: {severity: INFORMATION} {code: Neo.ClientNotification.Schema.IndexOrConstraintAlreadyExists} {category: SCHEMA} {title: `CREATE VECTOR INDEX entity IF NOT EXISTS FOR (e:__Entity__) ON (e.embedding)` has no effect.} {description: `VECTOR INDEX entity FOR (e:__Entity__) ON (e.embedding)` already exists.} {position: None} for query: 'CREATE VECTOR INDEX entity IF NOT EXISTS FOR (m:__Entity__) ON m.embedding'\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8389bc1e6347410aa82910e2512e1d9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Parsing nodes:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting paths from text with schema:   0%|             | 0/5 [00:00<?, ?it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Extracting paths from text with schema:  20%|█    | 1/5 [00:09<00:37,  9.40s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Extracting paths from text with schema:  40%|██   | 2/5 [00:10<00:14,  4.69s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Extracting paths from text with schema:  60%|███  | 3/5 [00:11<00:05,  2.93s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Extracting paths from text with schema:  80%|████ | 4/5 [00:17<00:04,  4.07s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Extracting paths from text with schema: 100%|█████| 5/5 [00:27<00:00,  5.60s/it]\n",
      "Generating embeddings:   0%|                              | 0/1 [00:00<?, ?it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████████████████| 1/1 [00:00<00:00,  1.64it/s]\n",
      "Generating embeddings:   0%|                              | 0/1 [00:00<?, ?it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████████████████| 1/1 [00:00<00:00,  1.09it/s]\n",
      "INFO:neo4j.notifications:Received notification from DBMS server: {severity: INFORMATION} {code: Neo.ClientNotification.Schema.IndexOrConstraintAlreadyExists} {category: SCHEMA} {title: `CREATE CONSTRAINT IF NOT EXISTS FOR (e:__Node__) REQUIRE (e.id) IS UNIQUE` has no effect.} {description: `CONSTRAINT constraint_ec67c859 FOR (e:__Node__) REQUIRE (e.id) IS UNIQUE` already exists.} {position: None} for query: 'CREATE CONSTRAINT IF NOT EXISTS FOR (n:`__Node__`)\\n            REQUIRE n.id IS UNIQUE;'\n",
      "INFO:neo4j.notifications:Received notification from DBMS server: {severity: INFORMATION} {code: Neo.ClientNotification.Schema.IndexOrConstraintAlreadyExists} {category: SCHEMA} {title: `CREATE CONSTRAINT IF NOT EXISTS FOR (e:__Entity__) REQUIRE (e.id) IS UNIQUE` has no effect.} {description: `CONSTRAINT constraint_907a464e FOR (e:__Entity__) REQUIRE (e.id) IS UNIQUE` already exists.} {position: None} for query: 'CREATE CONSTRAINT IF NOT EXISTS FOR (n:`__Entity__`)\\n            REQUIRE n.id IS UNIQUE;'\n",
      "INFO:neo4j.notifications:Received notification from DBMS server: {severity: INFORMATION} {code: Neo.ClientNotification.Schema.IndexOrConstraintAlreadyExists} {category: SCHEMA} {title: `CREATE VECTOR INDEX entity IF NOT EXISTS FOR (e:__Entity__) ON (e.embedding)` has no effect.} {description: `VECTOR INDEX entity FOR (e:__Entity__) ON (e.embedding)` already exists.} {position: None} for query: 'CREATE VECTOR INDEX entity IF NOT EXISTS FOR (m:__Entity__) ON m.embedding'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File Excel salvato in: valutazioni_clinical_.xlsx\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "499728cde0c741d7afe96085e50df29a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Parsing nodes:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting paths from text with schema:   0%|             | 0/5 [00:00<?, ?it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Extracting paths from text with schema:  20%|█    | 1/5 [00:07<00:31,  7.76s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Extracting paths from text with schema:  40%|██   | 2/5 [00:08<00:10,  3.42s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Extracting paths from text with schema:  60%|███  | 3/5 [00:08<00:04,  2.06s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Extracting paths from text with schema:  80%|████ | 4/5 [00:13<00:03,  3.38s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Extracting paths from text with schema: 100%|█████| 5/5 [00:29<00:00,  5.95s/it]\n",
      "Generating embeddings:   0%|                              | 0/1 [00:00<?, ?it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████████████████| 1/1 [00:00<00:00,  1.73it/s]\n",
      "Generating embeddings:   0%|                              | 0/1 [00:00<?, ?it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████████████████| 1/1 [00:01<00:00,  1.31s/it]\n",
      "INFO:neo4j.notifications:Received notification from DBMS server: {severity: INFORMATION} {code: Neo.ClientNotification.Schema.IndexOrConstraintAlreadyExists} {category: SCHEMA} {title: `CREATE CONSTRAINT IF NOT EXISTS FOR (e:__Node__) REQUIRE (e.id) IS UNIQUE` has no effect.} {description: `CONSTRAINT constraint_ec67c859 FOR (e:__Node__) REQUIRE (e.id) IS UNIQUE` already exists.} {position: None} for query: 'CREATE CONSTRAINT IF NOT EXISTS FOR (n:`__Node__`)\\n            REQUIRE n.id IS UNIQUE;'\n",
      "INFO:neo4j.notifications:Received notification from DBMS server: {severity: INFORMATION} {code: Neo.ClientNotification.Schema.IndexOrConstraintAlreadyExists} {category: SCHEMA} {title: `CREATE CONSTRAINT IF NOT EXISTS FOR (e:__Entity__) REQUIRE (e.id) IS UNIQUE` has no effect.} {description: `CONSTRAINT constraint_907a464e FOR (e:__Entity__) REQUIRE (e.id) IS UNIQUE` already exists.} {position: None} for query: 'CREATE CONSTRAINT IF NOT EXISTS FOR (n:`__Entity__`)\\n            REQUIRE n.id IS UNIQUE;'\n",
      "INFO:neo4j.notifications:Received notification from DBMS server: {severity: INFORMATION} {code: Neo.ClientNotification.Schema.IndexOrConstraintAlreadyExists} {category: SCHEMA} {title: `CREATE VECTOR INDEX entity IF NOT EXISTS FOR (e:__Entity__) ON (e.embedding)` has no effect.} {description: `VECTOR INDEX entity FOR (e:__Entity__) ON (e.embedding)` already exists.} {position: None} for query: 'CREATE VECTOR INDEX entity IF NOT EXISTS FOR (m:__Entity__) ON m.embedding'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File Excel salvato in: valutazioni_clinical_.xlsx\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89526b8920194a4cbffbfa52c0a07593",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Parsing nodes:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting paths from text with schema:   0%|             | 0/5 [00:00<?, ?it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Extracting paths from text with schema:  20%|█    | 1/5 [00:06<00:27,  6.88s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Extracting paths from text with schema:  40%|██   | 2/5 [00:07<00:09,  3.23s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Extracting paths from text with schema:  60%|███  | 3/5 [00:08<00:04,  2.20s/it]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Extracting paths from text with schema: 100%|█████| 5/5 [00:15<00:00,  3.10s/it]\n",
      "Generating embeddings:   0%|                              | 0/1 [00:00<?, ?it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████████████████| 1/1 [00:00<00:00,  1.64it/s]\n",
      "Generating embeddings:   0%|                              | 0/1 [00:00<?, ?it/s]INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "Generating embeddings: 100%|██████████████████████| 1/1 [00:00<00:00,  3.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File Excel salvato in: valutazioni_clinical_.xlsx\n"
     ]
    }
   ],
   "source": [
    "# Esempio di utilizzo\n",
    "# iterate through all file\n",
    "path = \"/Users/marcocalamo/Downloads/Clinical_History/\"\n",
    "for file in os.listdir(path): \n",
    "    # Check whether file is in text format or not \n",
    "    if file.endswith(\".txt\"): \n",
    "        file_path = f\"{path}{file}\"\n",
    "  \n",
    "        # call read text file function \n",
    "        genera_excel_con_valutazione(file_path, \"valutazioni_clinical.xlsx\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
